{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tensorflow_model_analysis.eval_saved_model.post_export_metrics import post_export_metrics\n",
    "from tensorflow_model_analysis.slicer import slicer\n",
    "from tensorflow_transform.coders import example_proto_coder\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "from tensorflow_transform import coders as tft_coders\n",
    "import apache_beam as beam\n",
    "from config import REGION, BUCKET, PROJECT, DELIM, RENAMED_COLS, STRING_COLS, NUMERIC_COLS, LABEL_COL, TOKENIZE_COL, NGRAM_RANGE, MAX_TOKENS\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_spec = [\n",
    "    slicer.SingleSliceSpec()\n",
    "]\n",
    "\n",
    "def decode_csv(row):\n",
    "    try:\n",
    "        split = row.split(DELIM)\n",
    "        features = dict(zip(RENAMED_COLS, split))\n",
    "        for col in STRING_COLS:\n",
    "            features[col] = features[col].strip()\n",
    "        for col in NUMERIC_COLS:\n",
    "            features[col] = float(features[col])\n",
    "    except ValueError:\n",
    "        features = {}\n",
    "        for col in STRING_COLS:\n",
    "            features[col] = ''.join(['dummy_', col])\n",
    "        for col in NUMERIC_COLS:\n",
    "            features[col] = 0.0\n",
    "    finally:\n",
    "        all_cols = STRING_COLS + NUMERIC_COLS\n",
    "        for key in features.keys():\n",
    "            if key not in all_cols:\n",
    "                features.pop(key)\n",
    "        return features\n",
    "\n",
    "def process_tfma(on_cloud=False):\n",
    "    import tensorflow_model_analysis as tfma\n",
    "    from tensorflow_model_analysis.eval_saved_model.post_export_metrics import post_export_metrics\n",
    "    from tensorflow_model_analysis.slicer import slicer\n",
    "    from tensorflow_transform.coders import example_proto_coder\n",
    "    from tensorflow_transform.tf_metadata import dataset_schema\n",
    "    from tensorflow_transform import coders as tft_coders\n",
    "    from config import PROJECT, BUCKET\n",
    "    import os\n",
    "    import datetime\n",
    "    from glob import glob\n",
    "    \n",
    "    job_name = 'preprocess-for-tfma-{project}-'.format(project=PROJECT) + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    \n",
    "    if on_cloud:\n",
    "        print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "        OUTPUT_DIR = 'gs://{bucket}/spam-classification/model_trained/eval/tfma/evaluated'.format(bucket=BUCKET)\n",
    "        import subprocess\n",
    "        subprocess.call('gsutil rm -r {}'.format(OUTPUT_DIR).split())\n",
    "    else:\n",
    "        import shutil\n",
    "        print('Launching local job ... hang on')\n",
    "        OUTPUT_DIR = './model_trained/eval/tfma/evaluated'\n",
    "        shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "\n",
    "    options = {\n",
    "        'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'max_num_workers': 24,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True,\n",
    "        'requirements_file': 'requirements.txt'\n",
    "    }\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    \n",
    "    if on_cloud:\n",
    "        RUNNER = 'DataflowRunner'\n",
    "        input_csv = './data/split/eval.csv'\n",
    "    else:\n",
    "        RUNNER = 'DirectRunner'\n",
    "        input_csv = 'gs://{bucket}/{project}/model_trained/eval/tfma/evaluated'.format(bucket=BUCKET, project=PROJECT)\n",
    "        \n",
    "    with beam.Pipeline(RUNNER, options=opts) as pipeline:       \n",
    "        eval_data = (\n",
    "            pipeline | \n",
    "            'read_eval_data' >> beam.io.ReadFromTFRecord('./data/tft/eval*.gz')\n",
    "        )\n",
    "        \n",
    "        _ = (\n",
    "            eval_data\n",
    "            | 'evaluate_and_write_results' >> tfma.EvaluateAndWriteResults(\n",
    "                eval_saved_model_path=glob('model_trained/eval/tfma/*')[-1],\n",
    "                slice_spec=slice_spec,\n",
    "#                 add_metrics_callbacks=[\n",
    "#                     post_export_metrics.calibration_plot_and_prediction_histogram(),\n",
    "#                     post_export_metrics.auc_plots()\n",
    "#                 ],\n",
    "                output_path=OUTPUT_DIR\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching local job ... hang on\n",
      "INFO:tensorflow:Restoring parameters from model_trained/eval/tfma/1534067348/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_trained/eval/tfma/1534067348/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_trained/eval/tfma/1534067348/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_trained/eval/tfma/1534067348/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_trained/eval/tfma/1534067348/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_trained/eval/tfma/1534067348/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_trained/eval/tfma/1534067348/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_trained/eval/tfma/1534067348/variables/variables\n"
     ]
    }
   ],
   "source": [
    "process_tfma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
