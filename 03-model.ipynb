{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ejuHKQ9UfSMJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install tensorflow-transform\n",
        "pip install apache-beam[gcp]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nSkew8KnU3qJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "from __future__ import print_function, division, absolute_import # python 2 compatibility\n",
        "import tensorflow as tf\n",
        "from tensorflow_transform.saved import input_fn_maker, saved_transform_io\n",
        "from tensorflow_transform.tf_metadata import metadata_io\n",
        "import tensorflow_hub as hub\n",
        "import apache_beam as beam\n",
        "import shutil\n",
        "import os\n",
        "print(tf.__version__)\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VYAQsX-rVK3H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "REGION = 'asia-east1'\n",
        "BUCKET = '{BUCKET}'\n",
        "PROJECT = '{PROJECT}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EBEdbhATWPmL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Cloud Setup\n",
        "This section is required only if running on cloud (ML Engine)"
      ]
    },
    {
      "metadata": {
        "id": "mHu_5_dqrssE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.environ['PROJECT'] = PROJECT\n",
        "os.environ['BUCKET'] = BUCKET\n",
        "os.environ['REGION'] = REGION\n",
        "os.environ['TFVERSION'] = '1.9'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ia9n5ZtEWFks",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%bash\n",
        "gcloud config set project $PROJECT\n",
        "gcloud config set compute/region $REGION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CRKcKSb6Wnyr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Data\n",
        "Data is assumed to be in the `TFRecords` format with GZIP compression. This gets us the best performance and scalability compared to csv files. The conversion of `csv` to `TFRecords` should be done in the previous notebook, `02-tf_transform.ipynb`"
      ]
    },
    {
      "metadata": {
        "id": "Vd0BxJv5soe1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wbkA9Vd_tKzU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up Model as a Package\n",
        "We need to set up our model as a package for training and serving.\n",
        "\n",
        "- `model.py` provides the code for data inputs and the model itself\n",
        "- `setup.py` provides metadata about the package\n",
        "- `task.py` sets up the package to be used from the command line, with arguments that specify hyperparameters to the model as well as GCP resources "
      ]
    },
    {
      "metadata": {
        "id": "C952m8_sWKJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile model.py --append\n",
        "\n",
        "\n",
        "CSV_COLUMNS = ['spam', 'text']\n",
        "LABEL_COLUMN = 'spam'\n",
        "DEFAULTS = [['spam'], [\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, 1.50 to rcv\"]]\n",
        "INPUT_COLUMNS = [\n",
        "    tf.placeholder(tf.string, name='text')\n",
        "]\n",
        "\n",
        "\n",
        "def build_estimator(model_dir, model_type, embedding_type, learning_rate,\n",
        "                    hidden_units, dropout,\n",
        "                    l1_regularization_strength, l2_regularization_strength):\n",
        "    (text) = INPUT_COLUMNS\n",
        "  \n",
        "    if embedding_type == 'nnlm':\n",
        "        module_url = 'https://tfhub.dev/google/nnlm-en-dim128/1'\n",
        "        embedding_size = 128\n",
        "    elif embedding_type == 'universal-sentence-encoder':\n",
        "        module_url = 'https://tfhub.dev/google/universal-sentence-encoder/2'\n",
        "        embedding_size = 512\n",
        "    elif embedding_type == 'elmo':\n",
        "        module_url = 'https://tfhub.dev/google/elmo/2'\n",
        "        embedding_size = 1024\n",
        "    elif embedding_type is None:\n",
        "        pass\n",
        "    else:\n",
        "        raise InputError('Embedding type must be one of \"nnlm\", \"universal-sentence-encoder\", \"elmo\", None')\n",
        "    \n",
        "    if embedding_type is not None:\n",
        "        embed = hub.Module(module_url, trainable=False)\n",
        "        embedding = embed(text)\n",
        "    \n",
        "    if model_type == 'linear':\n",
        "        return tf.estimator.LinearClassifier(\n",
        "            feature_columns=[embedding],\n",
        "            n_classes=2,\n",
        "            model_dir=model_dir,\n",
        "            optimizer=tf.train.FtrlOptimizer(\n",
        "                learning_rate=learning_rate,\n",
        "                l1_regularization_strength=l1_regularization_strength,\n",
        "                l2_regularization_strength=l2_regularization_strength\n",
        "            )\n",
        "        )\n",
        "    elif model_type == 'dnn':\n",
        "        return tf.estimator.DNNClassifier(\n",
        "            feature_columns=[embedding],\n",
        "            hidden_units=hidden_units,\n",
        "            n_classes=2,\n",
        "            model_dir=model_dir,\n",
        "            optimizer=tf.train.AdamOptimizer(\n",
        "                learning_rate=learning_rate,\n",
        "            ),\n",
        "            dropout=dropout\n",
        "        )\n",
        "    else:\n",
        "        raise InputErorr('Model type must be one of \"linear\" or \"dnn\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0l1scrAJtUQk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}