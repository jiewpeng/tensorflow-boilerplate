{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JolileErHCaH"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQu1f-QmGexE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import csv\n",
    "import config\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8e1gHCT4GlCH"
   },
   "source": [
    "# Cloud Setup\n",
    "This section is only required if running on cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJnHrsFHGlVQ"
   },
   "outputs": [],
   "source": [
    "os.environ['BUCKET'] = config.BUCKET\n",
    "os.environ['PROJECT'] = config.PROJECT\n",
    "os.environ['REGION'] = config.REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otbgjhTeGn-f"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2O9fiCiOGrxu"
   },
   "source": [
    "# Data Profiling\n",
    "Data profiling is done to better understand the data, and to see if there are any invalid data (e.g. out of bounds data, unexpected data types). No data preprocessing should be done here; it should be done in tf.transform so as to have a consistent data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fXLiBBpGsFY",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('data/raw/spam*.csv')\n",
    "df = pd.concat([pd.read_csv(f, usecols=config.RAW_DATA_COLS) for f in files], ignore_index=True)\n",
    "df.columns = config.RENAMED_COLS\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-y2ucs2jHPrX"
   },
   "outputs": [],
   "source": [
    "ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmEgecH0HRgZ"
   },
   "source": [
    "# Split Data\n",
    "Example uses 80-10-10 split for train, eval and test - change if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_dc6vYGGv0H"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "train_df = df.sample(frac=0.8, random_state=RANDOM_SEED)\n",
    "eval_df = df.drop(train_df.index)\n",
    "test_df = eval_df.sample(frac=0.5, random_state=RANDOM_SEED)\n",
    "eval_df = eval_df.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlsukCL7I9sg"
   },
   "outputs": [],
   "source": [
    "def export_datasets(on_cloud=False):\n",
    "    if on_cloud:\n",
    "        data_dir = 'gs://{bucket}/spam-classification/data/split'.format(bucket=config.BUCKET)\n",
    "    else:\n",
    "        data_dir = 'data/split'\n",
    "    \n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    if not os.path.exists('data/split'):\n",
    "        os.mkdir('data/split')\n",
    "    \n",
    "    def export_df(df, filename):\n",
    "        full_path = os.path.join(data_dir, filename)\n",
    "        csv_str = '\\n'.join(config.DELIM.join(str(r) for r in rec) for rec in df.to_records(index=False))\n",
    "        with open(full_path, 'w') as f:\n",
    "            f.write(csv_str)\n",
    "    \n",
    "    export_df(train_df, 'train.csv')\n",
    "    export_df(eval_df, 'eval.csv')\n",
    "    export_df(test_df, 'test.csv')\n",
    "    \n",
    "    label_vocab = list(df[config.LABEL_COL].unique())\n",
    "    n_classes = len(label_vocab)\n",
    "    \n",
    "    if not os.path.exists('data/misc'):\n",
    "        os.mkdir('data/misc')\n",
    "    with open('./data/misc/labels.txt', 'w') as f:\n",
    "        f.write('\\n'.join(label_vocab))\n",
    "    with open('variables.py', 'w') as f:\n",
    "        f.write(\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "LABEL_TO_INDEX = tf.contrib.lookup.index_table_from_file(\n",
    "    './data/misc/labels.txt',\n",
    "    default_value=-1,\n",
    "    num_oov_buckets=1\n",
    ")\n",
    "\n",
    "INDEX_TO_LABEL = tf.contrib.lookup.index_to_string_table_from_file(\n",
    "    './data/misc/labels.txt',\n",
    "    default_value='ham'\n",
    ")\n",
    "\n",
    "N_CLASSES = {n_classes}\n",
    "LABEL_VOCABULARY = {label_vocab}\n",
    "\n",
    "\"\"\".format(n_classes=n_classes, label_vocab=label_vocab))\n",
    "        \n",
    "    return\n",
    "  \n",
    "export_datasets(on_cloud=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-data_preproc.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
